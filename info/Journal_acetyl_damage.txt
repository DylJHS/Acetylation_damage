Prior:
- Collected sample folders containing raw FASTQ files for analysis.
- Assessed sequence quality using FastQC, revealing manageable overall quality, though slight trimming was required due to minor quality issues identified.
- Trimmed adapter sequences and low-quality reads using Trim Galore, resulting in improved overall read quality.

- Initially downloaded the Drosophila melanogaster reference genome (dm6 version) and constructed the Bowtie2 index for aligning sequencing reads.
- Attempted alignments of trimmed FASTQ files to the Drosophila reference genome resulted in unexpectedly low alignment rates (approximately 1-4% across all samples).
- Suspecting an issue with the genome version, a different Drosophila reference genome from Ensembl.org was obtained and indexed, but the alignment performance did not improve significantly.

- Due to persistently poor alignments, decided to investigate the source of sequences by extracting a smaller subset (100-500 reads) from sample FASTQ files and converting them to FASTA format.
- Initial BLAST queries through the NCBI website indicated reads predominantly matched human sequences, along with other organisms such as mouse and fungi, with no significant matches to Drosophila melanogaster.
- Conducted a more comprehensive BLAST analysis locally, building separate BLAST databases for the human and Drosophila genomes.
- BLAST analyses against the human genome consistently showed significantly higher alignment rates (ranging from 2.8% to 70.3%), with millions of hits and high identity percentages averaging around 90%.
- In contrast, BLAST queries against the Drosophila database yielded very low alignment rates (ranging from 0.0% to 0.7%), with minimal numbers of hits.

Summary Interpretation:
The data strongly indicates contamination of the Drosophila sequencing samples with human genomic material, explaining the initially poor alignment rates to the Drosophila reference genome. High human alignment percentages, with substantial average identity scores (~89%-98%) and lower mismatch rates, confirm human DNA as the predominant component in the sequencing data. 

07/05/25:
- Validating the experiment was not run on the human (mostly) samples
- Need to assess the level of acetylation across the samples
- Using the bam files that were generated during the initial analysis 
- removing the duplicates from the files using markdup in Samtools
- "samtools_pcr_duplicate_removal_loop.sh" is the hpc script which loops over the bam fiels and performs the removal

08/05/25:
- Ran the script 
- Debugged the script (mainly conda env issues)
- Got the resulting de-duplicated files but issue with the looping
- modified script to only loop over the original JAN-00?.bam files
- the dedup script removed most of the reads 
- reran with proper fixmate args and get better results

09/05/25: 
- Looking at the resutls from the plotFingerprint from deepTools shows that the controls and the induced samples seem to have the same level of enrichment for the human alignment
- This should not be the case
- the control line and the induced "input" lines should deviate with the induced ones showing increased enrichment (more of an elbow in the plot)
- But not seeing a difference between the induced and control is not indicative of there being an issue 
- It could just mean that the null hypothesis is true and there is no acetylation difference 
- But would still expect a higher curve due to the marks being a broad mark
- Ran the scrtips on the "tagged" bam files which show better results but not sure where they come from and how they were produced
- Will continue the analysis on tagged and untagged and assess the differences
- Generating the bamCoverages for the data

13/05/25
- generating the bigwig files for the fly data
- Checking the coverages in IGV 

14/05/25
- Running the integration_site_test scripts 
- Generating the RPKM bigwig files for better comparison between samples 
- Generating the counts.txt file for the quantitative data in order to test between the samples at the integration int_site
- Need to perform a comparitive test betweent the counts "integration_counts.txt"
- Will perform a Fisher's exact test 

15/05/25
- Ran the Fisher exact test for the coverage from 22245250 to 22245350 (100bp) 
- The test did not reveal anything significant likely due to the high degree of background reads
- Emailed Arianna with some of the findings and the IGV tracks 

25/05/25
- Trying to find out the source of the issue with SCC
- Need to give a recommendation for the sequencing depth 

10/07/25
- Downloaded the newly run data from SCC 
- stored in: P:\Janssen\chet_repair\dhaynessimmons\raw_data\fly_acetylation_damage\SCC-bulkChIC-UMC-JULY.tar.gz

11/07/25
- Unzipping the folders in the Projects dir 

12/07/25
- Sending the new SCC files ot the HPC server to run the analyses
- Need to check the data

14/07/25
- Going over the fly_acetylation_damage scripts and noticed that they need better descriptions and titles (comments are good though)
- Looking first at the BLAST scripts since those are the ones that will be used first
- Combing the BLAST scripts into a single bash script for the hpc server
- The increase in the read depth means that more lanes were used instead of just one
- This may impact the file strucutres and how they are used in the scripts

15/07/25
- Re-extracting the SCC folder since only 4 samples were perviously in the decompressed folder
- All samples are present in the new decompression
- Combining the BLAST scripts all in one
- Running the full script on all 6 samples
- the BLAST results seem to show the same kind of relation to the human genome instead of the drosophila ones
- run again with more stringent evalue 1e-10

16/07/25
- The results from the previous run were better but still showed better correlation with the human genome than the drosophila
- Restricted the parameters more for more stringent query: 
    - task megablast
    - perc_identity = 95
    - ungapped
    - evalue = 1e-20
- Converting the BLASTn query and the FASTA_generation scripts to handle array jobs for faster runtime "BLASTn_arr.sh"
- Still need to create a single launch script (FASTA gen + BLASTn query + results summary file gen)

17/07/25
- Creation of BLAST config file "BLAST_wkflw_config.sh" to reference for all the inner jobs
- Creation of BLAST workflow script to run the full pipeline with all 3 jobs (gen_fasta_subsets_arr.sh, BLASTn_arr.sh & gen_blast_summary.sh) => "run_blast_wkflw.sh"
- Rerun the BLASTn query using the following stringent args: 
    -task megablast \
    -perc_identity 95 \
    -max_target_seqs 1 \
    -max_hsps 1 \
    -ungapped \
    -evalue 1e-20 \
- Still showing better results for the human BLAST query than the fly despite the stricter settings
- Going to trim, qc, align and then see the data
- Ran the multiqc
- High duplication rate means that high pcr bias or oversequencing due to low complexity (common in ChIC seq) 
- Need to deduplicate 
- Higher R1 read duplication than R2 for all fastq files; might be normal due to the cutting process of the Mnase
- MultiQC report duplicate rates are likely higher than the actual duplicate rates due to how they only assess the first 50 bp of the reads 


22/07/25
- Trimming the reads
- Trimmed reads added to the trimmed_fastq folder in the data dir 
- Also added to the config file
- Built the drosophila bowtie2 index using the "fly_build_bowtie2_index.sh" script
- Concatenating the trimmed reads across lanes into single files for each sample
- Need to run MultiQC on the trimmed reads to assess the quality
- Issues running trim galore due to bug when using multiple cores 
- Removing cores to see if it resolves the issue
- Could also be due to how the script runs. Once in single mode and then in paired mode

23/07/25
- Changing the trim_fastq_galore.sh script to only run the trim command 
- Need to build new script that then concatenates the trimmed reads across lanes into single files for each sample
- running the fastqc & multiqc commands on the trimmed reads
- Concatenating the trimmed reads across lanes into merged files using concat_fastq.sh script
- results from the trimming and subsequent qc did not show significant improvements
- Rerunning the trim galore script with clip argument on the first 6bp 
- stringnecy set to 3 for better trimming
